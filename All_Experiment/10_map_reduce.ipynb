{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b4ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbb52b72",
   "metadata": {},
   "source": [
    "## Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71ba6a5",
   "metadata": {},
   "source": [
    "```\n",
    "START\n",
    "  ‚Üì\n",
    "ORCHESTRATOR (splits PDF into chunks)\n",
    "  ‚Üì ‚Üì ‚Üì ‚Üì ‚Üì (parallel)\n",
    "MAP 0   MAP 1   MAP 2 ... MAP N\n",
    "  ‚Üì ‚Üì ‚Üì ‚Üì ‚Üì\n",
    "REDUCE (merge summaries)\n",
    "  ‚Üì\n",
    "END\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d472e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7f88c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11d560920>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# langgraph_mapreduce_wordcount.py\n",
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send, Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# ---- State types ----\n",
    "class AggregateState(TypedDict, total=False):\n",
    "    docs: List[str]\n",
    "    # Annotate partials with a reducer (list concatenation)\n",
    "    partials: Annotated[List[Dict[str,int]], add]\n",
    "    final_counts: Dict[str,int]\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    doc: str\n",
    "\n",
    "# ---- Orchestrator: fan-out map jobs ----\n",
    "def orchestrator(state: AggregateState) -> Command:\n",
    "    docs = state.get(\"docs\", []) or []\n",
    "    sends = [Send(\"map_doc\", {\"doc\": d}) for d in docs]\n",
    "    # return a Command that dispatches multiple Sends\n",
    "    return Command(update={}, goto=sends)\n",
    "\n",
    "# ---- Map node: count words in a single document ----\n",
    "def map_doc(state: WorkerState) -> Dict[str, List[Dict[str,int]]]:\n",
    "    text = state.get(\"doc\", \"\")\n",
    "    counts: Dict[str,int] = {}\n",
    "    for token in text.split():\n",
    "        w = token.lower().strip(\".,!?:;\\\"'()[]\")\n",
    "        if not w:\n",
    "            continue\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "    # return as a one-element list under 'partials' so reducer concatenates lists\n",
    "    return {\"partials\": [counts]}\n",
    "\n",
    "# ---- Reduce node: combine all partial counts ----\n",
    "def reducer(state: AggregateState) -> Dict[str, Dict[str,int]]:\n",
    "    final: Dict[str,int] = {}\n",
    "    for part in state.get(\"partials\", []):\n",
    "        for word, cnt in part.items():\n",
    "            final[word] = final.get(word, 0) + cnt\n",
    "    return {\"final_counts\": final}\n",
    "\n",
    "# ---- Build graph ----\n",
    "def build_mapreduce_graph() -> StateGraph:\n",
    "    builder = StateGraph(AggregateState)\n",
    "\n",
    "    builder.add_node(\"orchestrator\", orchestrator)\n",
    "    builder.add_node(\"map_doc\", map_doc)\n",
    "    builder.add_node(\"reduce\", reducer)\n",
    "\n",
    "    builder.add_edge(START, \"orchestrator\")\n",
    "    # map_doc results feed into reduce\n",
    "    builder.add_edge(\"map_doc\", \"reduce\")\n",
    "    builder.add_edge(\"reduce\", END)\n",
    "\n",
    "    graph = builder.compile(checkpointer=InMemorySaver())\n",
    "    return graph\n",
    "\n",
    "graph= build_mapreduce_graph()\n",
    "\n",
    "graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395808ad",
   "metadata": {},
   "source": [
    "## ‚ÄúLangGraph graph diagrams do not show dynamic fan-out edges created using Send.\n",
    "## These edges exist only at runtime.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362716e",
   "metadata": {},
   "source": [
    "```\n",
    "START\n",
    "  ‚Üì\n",
    "orchestrator\n",
    "  ‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì\n",
    "map_doc map_doc map_doc   (parallel)\n",
    "      ‚Üì   ‚Üì   ‚Üì\n",
    "        reduce\n",
    "           ‚Üì\n",
    "          END\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9585096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final word counts: {'peak': 2, 'performance': 2, 'gym': 5, 'was': 1, 'founded': 1, 'in': 2, '2015': 1, 'by': 1, 'former': 1, 'olympic': 1, 'athlete': 1, 'marcus': 2, 'chen': 1, 'with': 4, 'over': 1, '15': 1, 'years': 1, 'of': 3, 'experience': 1, 'professional': 1, 'athletics': 1, 'established': 1, 'the': 2, 'to': 4, 'provide': 1, 'personalized': 1, 'fitness': 1, 'solutions': 1, 'for': 2, 'people': 1, 'all': 2, 'levels': 1, 'spans': 1, '10,000': 1, 'square': 1, 'feet': 1, 'and': 5, 'features': 1, 'state-of-the-art': 1, 'equipment': 2, 'is': 1, 'open': 1, 'monday': 1, 'through': 1, 'friday': 1, 'from': 1, '5:00': 1, 'am': 2, '11:00': 1, 'pm': 2, 'on': 3, 'weekends': 1, 'our': 2, 'hours': 1, 'are': 2, '7:00': 1, '9:00': 1, 'we': 2, 'remain': 1, 'closed': 1, 'major': 1, 'national': 1, 'holidays': 2, 'members': 1, 'premium': 2, 'access': 3, 'can': 1, 'enter': 1, 'using': 1, 'their': 1, 'key': 1, 'cards': 1, '24/7': 2, 'including': 1, 'membership': 1, 'plans': 2, 'include': 1, 'basic': 2, '‚Çπ1,500/month': 1, 'floor': 1, 'standard': 1, '‚Çπ2,500/month': 1, 'adds': 1, 'group': 1, 'classes': 1, 'locker': 1, 'facilities': 2, '‚Çπ4,000/month': 1, 'includes': 1, 'personal': 1, 'training': 1, 'sessions': 1, 'spa': 1, 'offer': 1, 'student': 1, 'senior': 1, 'citizen': 1, 'discounts': 1, '15%': 1, 'corporate': 1, 'partnerships': 1, 'available': 1, 'companies': 1, '10+': 1, 'employees': 1, 'joining': 1}\n"
     ]
    }
   ],
   "source": [
    "# ---- Run example ----\n",
    "if __name__ == \"__main__\":\n",
    "    # docs = [\n",
    "    #     \"Hello world hello\",\n",
    "    #     \"World of code and Hello\",\n",
    "    #     \"Another document. Code world!\"\n",
    "    # ]\n",
    "    \n",
    "    docs= [\n",
    "        \"Peak Performance Gym was founded in 2015 by former Olympic athlete Marcus Chen. With over 15 years of experience in professional athletics, Marcus established the gym to provide personalized fitness solutions for people of all levels. The gym spans 10,000 square feet and features state-of-the-art equipment.\",\n",
    "        \"Peak Performance Gym is open Monday through Friday from 5:00 AM to 11:00 PM. On weekends, our hours are 7:00 AM to 9:00 PM. We remain closed on major national holidays. Members with Premium access can enter using their key cards 24/7, including holidays.\",\n",
    "        \"Our membership plans include: Basic (‚Çπ1,500/month) with access to gym floor and basic equipment; Standard (‚Çπ2,500/month) adds group classes and locker facilities; Premium (‚Çπ4,000/month) includes 24/7 access, personal training sessions, and spa facilities. We offer student and senior citizen discounts of 15% on all plans. Corporate partnerships are available for companies with 10+ employees joining.\"\n",
    "    ]\n",
    "    initial_state: AggregateState = {\n",
    "        \"docs\": docs,\n",
    "        \"partials\": [],\n",
    "        \"final_counts\": {}\n",
    "    }\n",
    "\n",
    "    graph = build_mapreduce_graph()\n",
    "    config = {\"configurable\": {\"thread_id\": \"mapreduce_example_1\"}}\n",
    "\n",
    "    # invoke the graph (runs the orchestrator -> map -> reduce)\n",
    "    graph.invoke(initial_state, config=config)\n",
    "\n",
    "    # get the final StateSnapshot\n",
    "    snapshot = graph.get_state(config)\n",
    "\n",
    "    # IMPORTANT: snapshot is a StateSnapshot object ‚Äî values are in snapshot.values\n",
    "    final_counts = snapshot.values.get(\"final_counts\", {})\n",
    "\n",
    "    print(\"Final word counts:\", final_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90a14f",
   "metadata": {},
   "source": [
    "## From the PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "353f8b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x11e0d4440>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mapreduce_pdf_wordcount.py\n",
    "import os\n",
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from operator import add\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send, Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# PDF extraction\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load PDFs & split into chunks\n",
    "# -----------------------------\n",
    "\n",
    "def load_pdfs_as_chunks(folder: str, chunk_size: int = 1500) -> List[str]:\n",
    "    pdf_files = [f for f in os.listdir(folder) if f.lower().endswith(\".pdf\")]\n",
    "    all_chunks = []\n",
    "\n",
    "    for pdf in pdf_files:\n",
    "        path = os.path.join(folder, pdf)\n",
    "        print(f\"Reading PDF: {path}\")\n",
    "\n",
    "        raw_text = extract_text(path)\n",
    "        raw_text = raw_text.replace(\"\\n\", \" \")\n",
    "\n",
    "        # Split into chunks\n",
    "        chunks = []\n",
    "        words = raw_text.split()\n",
    "        current = []\n",
    "\n",
    "        for w in words:\n",
    "            current.append(w)\n",
    "            if len(current) >= chunk_size:\n",
    "                chunks.append(\" \".join(current))\n",
    "                current = []\n",
    "\n",
    "        if current:\n",
    "            chunks.append(\" \".join(current))\n",
    "\n",
    "        print(f\" -> extracted {len(chunks)} chunks from {pdf}\")\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Map-Reduce State Definitions\n",
    "# -----------------------------\n",
    "\n",
    "class AggregateState(TypedDict, total=False):\n",
    "    docs: List[str]\n",
    "    partials: Annotated[List[Dict[str,int]], add]\n",
    "    final_counts: Dict[str,int]\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    doc: str\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Map-Reduce Nodes\n",
    "# -----------------------------\n",
    "\n",
    "def orchestrator(state: AggregateState) -> Command:\n",
    "    docs = state.get(\"docs\", [])\n",
    "    sends = [Send(\"map_doc\", {\"doc\": d}) for d in docs]\n",
    "    return Command(update={}, goto=sends)\n",
    "\n",
    "def map_doc(state: WorkerState) -> Dict[str, List[Dict[str,int]]]:\n",
    "    text = state.get(\"doc\", \"\")\n",
    "    counts: Dict[str,int] = {}\n",
    "\n",
    "    for token in text.split():\n",
    "        w = token.lower().strip(\".,!?:;\\\"'()[]\")\n",
    "        if not w:\n",
    "            continue\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "\n",
    "    return {\"partials\": [counts]}  # reducer will merge lists\n",
    "\n",
    "def reducer(state: AggregateState) -> Dict[str, Dict[str,int]]:\n",
    "    final: Dict[str,int] = {}\n",
    "    for part in state.get(\"partials\", []):\n",
    "        for w, c in part.items():\n",
    "            final[w] = final.get(w, 0) + c\n",
    "    return {\"final_counts\": final}\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Build Graph\n",
    "# -----------------------------\n",
    "\n",
    "def build_mapreduce_graph() -> StateGraph:\n",
    "    builder = StateGraph(AggregateState)\n",
    "\n",
    "    builder.add_node(\"orchestrator\", orchestrator)\n",
    "    builder.add_node(\"map_doc\", map_doc)\n",
    "    builder.add_node(\"reduce\", reducer)\n",
    "\n",
    "    builder.add_edge(START, \"orchestrator\")\n",
    "    builder.add_edge(\"map_doc\", \"reduce\")\n",
    "    builder.add_edge(\"reduce\", END)\n",
    "\n",
    "    return builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "graph= build_mapreduce_graph()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba82a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loading PDFs...\n",
      "Reading PDF: /Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs/NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      " -> extracted 6 chunks from NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      "Reading PDF: /Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs/financial-statements.pdf\n",
      " -> extracted 27 chunks from financial-statements.pdf\n",
      "Total chunks for Map-Reduce: 33\n",
      "\n",
      "======================\n",
      "üìä FINAL WORD COUNTS:\n",
      "======================\n",
      "\n",
      "the                  1510\n",
      "of                   865\n",
      "and                  610\n",
      "-                    593\n",
      "a                    555\n",
      "in                   550\n",
      "to                   511\n",
      "e                    323\n",
      "as                   322\n",
      "31                   320\n",
      "march                309\n",
      "for                  289\n",
      "at                   283\n",
      "i                    282\n",
      "t                    264\n",
      "year                 262\n",
      "n                    248\n",
      "s                    247\n",
      "is                   244\n",
      "r                    236\n",
      "h                    226\n",
      "company              204\n",
      "are                  198\n",
      "2024                 193\n",
      "lakhs                188\n",
      "o                    183\n",
      "1                    182\n",
      "on                   173\n",
      "d                    163\n",
      "2                    158\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 5. Execution\n",
    "# -----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = r\"/Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs\"\n",
    "\n",
    "    print(\"üìÑ Loading PDFs...\")\n",
    "    docs = load_pdfs_as_chunks(folder, chunk_size=1000)\n",
    "\n",
    "    print(f\"Total chunks for Map-Reduce: {len(docs)}\")\n",
    "\n",
    "    initial_state: AggregateState = {\n",
    "        \"docs\": docs,\n",
    "        \"partials\": [],\n",
    "        \"final_counts\": {}\n",
    "    }\n",
    "\n",
    "    graph = build_mapreduce_graph()\n",
    "    config = {\"configurable\": {\"thread_id\": \"pdf_mr_wordcount\"}}\n",
    "\n",
    "    graph.invoke(initial_state, config=config)\n",
    "\n",
    "    snapshot = graph.get_state(config)\n",
    "    final_counts = snapshot.values.get(\"final_counts\", {})\n",
    "\n",
    "    print(\"\\n======================\")\n",
    "    print(\"üìä FINAL WORD COUNTS:\")\n",
    "    print(\"======================\\n\")\n",
    "\n",
    "    # print top 30 words\n",
    "    sorted_words = sorted(final_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "    for w, c in sorted_words[:30]:\n",
    "        print(f\"{w:<20} {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b5805e",
   "metadata": {},
   "source": [
    "## Without Map Reduce:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaa059a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loading PDFs...\n",
      "Reading PDF: /Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs/NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      " -> extracted 6 chunks from NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      "Reading PDF: /Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs/financial-statements.pdf\n",
      " -> extracted 27 chunks from financial-statements.pdf\n",
      "Total chunks for sequential processing: 33\n",
      "\n",
      "Processing 33 chunks sequentially...\n",
      "Processing chunk 0/33\n",
      "Processing chunk 10/33\n",
      "Processing chunk 20/33\n",
      "Processing chunk 30/33\n",
      "\n",
      "======================\n",
      "üìä FINAL WORD COUNTS (Sequential)\n",
      "======================\n",
      "\n",
      "the                  1510\n",
      "of                   865\n",
      "and                  610\n",
      "-                    593\n",
      "a                    555\n",
      "in                   550\n",
      "to                   511\n",
      "e                    323\n",
      "as                   322\n",
      "31                   320\n",
      "march                309\n",
      "for                  289\n",
      "at                   283\n",
      "i                    282\n",
      "t                    264\n",
      "year                 262\n",
      "n                    248\n",
      "s                    247\n",
      "is                   244\n",
      "r                    236\n",
      "h                    226\n",
      "company              204\n",
      "are                  198\n",
      "2024                 193\n",
      "lakhs                188\n",
      "o                    183\n",
      "1                    182\n",
      "on                   173\n",
      "d                    163\n",
      "2                    158\n",
      "\n",
      "‚è±Ô∏è TOTAL TIME (Sequential): 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# sequential_pdf_wordcount.py\n",
    "import os\n",
    "import time\n",
    "from typing import Dict, List\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 1. Load PDFs and split into chunks\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def load_pdfs_as_chunks(folder: str, chunk_size: int = 1500) -> List[str]:\n",
    "    pdf_files = [f for f in os.listdir(folder) if f.lower().endswith(\".pdf\")]\n",
    "    all_chunks = []\n",
    "\n",
    "    for pdf in pdf_files:\n",
    "        path = os.path.join(folder, pdf)\n",
    "        print(f\"Reading PDF: {path}\")\n",
    "\n",
    "        raw_text = extract_text(path)\n",
    "        raw_text = raw_text.replace(\"\\n\", \" \")\n",
    "\n",
    "        # Split into chunks\n",
    "        chunks = []\n",
    "        words = raw_text.split()\n",
    "        current = []\n",
    "\n",
    "        for w in words:\n",
    "            current.append(w)\n",
    "            if len(current) >= chunk_size:\n",
    "                chunks.append(\" \".join(current))\n",
    "                current = []\n",
    "\n",
    "        if current:\n",
    "            chunks.append(\" \".join(current))\n",
    "\n",
    "        print(f\" -> extracted {len(chunks)} chunks from {pdf}\")\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 2. Sequential word counting (NO MAP-REDUCE)\n",
    "# --------------------------------------------------------\n",
    "\n",
    "def word_count_sequential(chunks: List[str]) -> Dict[str, int]:\n",
    "    final_counts: Dict[str, int] = {}\n",
    "\n",
    "    print(f\"\\nProcessing {len(chunks)} chunks sequentially...\")\n",
    "\n",
    "    for idx, text in enumerate(chunks):\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Processing chunk {idx}/{len(chunks)}\")\n",
    "\n",
    "        words = text.split()\n",
    "        for token in words:\n",
    "            w = token.lower().strip(\".,!?:;\\\"'()[]\")\n",
    "            if not w:\n",
    "                continue\n",
    "            final_counts[w] = final_counts.get(w, 0) + 1\n",
    "\n",
    "    return final_counts\n",
    "\n",
    "# --------------------------------------------------------\n",
    "# 3. Run sequential process and measure time\n",
    "# --------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = r\"/Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs\"\n",
    "\n",
    "    print(\"üìÑ Loading PDFs...\")\n",
    "    chunks = load_pdfs_as_chunks(folder, chunk_size=1000)\n",
    "\n",
    "    print(f\"Total chunks for sequential processing: {len(chunks)}\")\n",
    "\n",
    "    start = time.time()\n",
    "    final_counts = word_count_sequential(chunks)\n",
    "    end = time.time()\n",
    "\n",
    "    print(\"\\n======================\")\n",
    "    print(\"üìä FINAL WORD COUNTS (Sequential)\")\n",
    "    print(\"======================\\n\")\n",
    "\n",
    "    sorted_words = sorted(final_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for w, c in sorted_words[:30]:\n",
    "        print(f\"{w:<20} {c}\")\n",
    "\n",
    "    print(\"\\n‚è±Ô∏è TOTAL TIME (Sequential):\", round(end - start, 2), \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26b72f5",
   "metadata": {},
   "source": [
    "## map reduce with timing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e754769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Loading PDFs...\n",
      "Reading PDF: /Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs/NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      " -> Extracted 6 chunks from NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      "Total chunks: 6\n",
      "\n",
      "===============================\n",
      "‚è±Ô∏è MAP-REDUCE TIMING RESULTS\n",
      "===============================\n",
      "\n",
      "MAP phase time:      0.0075 seconds\n",
      "REDUCE phase time:   0.0001 seconds\n",
      "TOTAL time:          0.0115 seconds\n",
      "\n",
      "Top 30 words:\n",
      "\n",
      "the                  279\n",
      "and                  155\n",
      "of                   152\n",
      "in                   110\n",
      "to                   102\n",
      "a                    74\n",
      "we                   66\n",
      "attention            55\n",
      "is                   43\n",
      "model                42\n",
      "for                  42\n",
      "on                   35\n",
      "with                 34\n",
      "models               33\n",
      "sequence             30\n",
      "as                   30\n",
      "our                  29\n",
      "this                 29\n",
      "output               27\n",
      "=                    27\n",
      "¬∑                    27\n",
      "neural               24\n",
      "layer                24\n",
      "self-attention       23\n",
      "translation          22\n",
      "positions            22\n",
      "input                22\n",
      "are                  21\n",
      "transformer          21\n",
      "layers               21\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from operator import add\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send, Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "# ============================\n",
    "# 1. Read PDFs ‚Üí chunks\n",
    "# ============================\n",
    "\n",
    "def load_pdfs_as_chunks(folder: str, chunk_size: int = 1500) -> List[str]:\n",
    "    pdf_files = [f for f in os.listdir(folder) if f.lower().endswith(\".pdf\")]\n",
    "    all_chunks = []\n",
    "\n",
    "    for pdf in pdf_files:\n",
    "        path = os.path.join(folder, pdf)\n",
    "        print(f\"Reading PDF: {path}\")\n",
    "\n",
    "        raw_text = extract_text(path).replace(\"\\n\", \" \")\n",
    "\n",
    "        words = raw_text.split()\n",
    "        chunks = []\n",
    "        current = []\n",
    "\n",
    "        for w in words:\n",
    "            current.append(w)\n",
    "            if len(current) >= chunk_size:\n",
    "                chunks.append(\" \".join(current))\n",
    "                current = []\n",
    "\n",
    "        if current:\n",
    "            chunks.append(\" \".join(current))\n",
    "\n",
    "        print(f\" -> Extracted {len(chunks)} chunks from {pdf}\")\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 2. Map-Reduce State\n",
    "# ============================\n",
    "\n",
    "class AggregateState(TypedDict, total=False):\n",
    "    docs: List[str]\n",
    "    partials: Annotated[List[Dict[str,int]], add]\n",
    "    final_counts: Dict[str,int]\n",
    "\n",
    "    # timing fields\n",
    "    map_start: float\n",
    "    map_end: float\n",
    "    reduce_start: float\n",
    "    reduce_end: float\n",
    "\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    doc: str\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 3. Nodes\n",
    "# ============================\n",
    "\n",
    "def orchestrator(state: AggregateState) -> Command:\n",
    "    \"\"\"Fan-out map tasks\"\"\"\n",
    "    docs = state.get(\"docs\", [])\n",
    "    sends = [Send(\"map_doc\", {\"doc\": d}) for d in docs]\n",
    "\n",
    "    # start MAP phase timer\n",
    "    return Command(\n",
    "        update={\"map_start\": time.time()},\n",
    "        goto=sends\n",
    "    )\n",
    "\n",
    "\n",
    "def map_doc(state: WorkerState) -> Dict[str, List[Dict[str,int]]]:\n",
    "    \"\"\"Map: count words in one chunk\"\"\"\n",
    "    text = state.get(\"doc\", \"\")\n",
    "    counts: Dict[str,int] = {}\n",
    "\n",
    "    for token in text.split():\n",
    "        w = token.lower().strip(\".,!?:;\\\"'()[]\")\n",
    "        if not w:\n",
    "            continue\n",
    "        counts[w] = counts.get(w, 0) + 1\n",
    "\n",
    "    return {\"partials\": [counts]}\n",
    "\n",
    "\n",
    "def reducer(state: AggregateState) -> Dict[str, Dict[str,int]]:\n",
    "    \"\"\"Reduce: combine all word counts\"\"\"\n",
    "    final: Dict[str,int] = {}\n",
    "\n",
    "    # end MAP phase when entering reducer\n",
    "    reduce_start = time.time()\n",
    "    update_time = {\"reduce_start\": reduce_start}\n",
    "\n",
    "    for part in state.get(\"partials\", []):\n",
    "        for w, c in part.items():\n",
    "            final[w] = final.get(w, 0) + c\n",
    "\n",
    "    # mark REDUCE end\n",
    "    update_time[\"reduce_end\"] = time.time()\n",
    "\n",
    "    # also mark MAP end only once (safe)\n",
    "    if \"map_end\" not in state:\n",
    "        update_time[\"map_end\"] = reduce_start\n",
    "\n",
    "    return {**update_time, \"final_counts\": final}\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 4. Build graph\n",
    "# ============================\n",
    "\n",
    "def build_mapreduce_graph() -> StateGraph:\n",
    "    builder = StateGraph(AggregateState)\n",
    "\n",
    "    builder.add_node(\"orchestrator\", orchestrator)\n",
    "    builder.add_node(\"map_doc\", map_doc)\n",
    "    builder.add_node(\"reduce\", reducer)\n",
    "\n",
    "    builder.add_edge(START, \"orchestrator\")\n",
    "    builder.add_edge(\"map_doc\", \"reduce\")\n",
    "    builder.add_edge(\"reduce\", END)\n",
    "\n",
    "    return builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 5. Main execution\n",
    "# ============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = r\"/Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs\"\n",
    "\n",
    "    print(\"üìÑ Loading PDFs...\")\n",
    "    docs = load_pdfs_as_chunks(folder, chunk_size=1000)\n",
    "    print(f\"Total chunks: {len(docs)}\")\n",
    "\n",
    "    initial_state: AggregateState = {\n",
    "        \"docs\": docs,\n",
    "        \"partials\": [],\n",
    "        \"final_counts\": {}\n",
    "    }\n",
    "\n",
    "    graph = build_mapreduce_graph()\n",
    "    config = {\"configurable\": {\"thread_id\": \"pdf_mr_timed\"}}\n",
    "\n",
    "    total_start = time.time()\n",
    "    graph.invoke(initial_state, config=config)\n",
    "    total_end = time.time()\n",
    "\n",
    "    snapshot = graph.get_state(config)\n",
    "    values = snapshot.values\n",
    "\n",
    "    # Timings\n",
    "    map_time = values[\"map_end\"] - values[\"map_start\"]\n",
    "    reduce_time = values[\"reduce_end\"] - values[\"reduce_start\"]\n",
    "    total_time = total_end - total_start\n",
    "\n",
    "    print(\"\\n===============================\")\n",
    "    print(\"‚è±Ô∏è MAP-REDUCE TIMING RESULTS\")\n",
    "    print(\"===============================\\n\")\n",
    "    print(f\"MAP phase time:      {map_time:.4f} seconds\")\n",
    "    print(f\"REDUCE phase time:   {reduce_time:.4f} seconds\")\n",
    "    print(f\"TOTAL time:          {total_time:.4f} seconds\\n\")\n",
    "\n",
    "    print(\"Top 30 words:\\n\")\n",
    "    final_counts = values[\"final_counts\"]\n",
    "    for w, c in sorted(final_counts.items(), key=lambda x: x[1], reverse=True)[:30]:\n",
    "        print(f\"{w:<20} {c}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e409dbb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a30bb52",
   "metadata": {},
   "source": [
    "## Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a122d6be",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d844766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PDF: NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      " ‚Üí Extracted 4 chunks\n",
      "\n",
      "Total Chunks: 4\n",
      "\n",
      "\n",
      "--- Sequential LLM Summaries ---\n",
      "\n",
      "Summarizing chunk 1/4 ...\n",
      " ‚Üí Chunk time: 1.37 sec\n",
      "Summarizing chunk 2/4 ...\n",
      " ‚Üí Chunk time: 1.31 sec\n",
      "Summarizing chunk 3/4 ...\n",
      " ‚Üí Chunk time: 1.52 sec\n",
      "Summarizing chunk 4/4 ...\n",
      " ‚Üí Chunk time: 0.7 sec\n",
      "\n",
      "==============================\n",
      "SEQUENTIAL SUMMARY TIMINGS\n",
      "==============================\n",
      "Total chunks: 4\n",
      "Chunk summarization time: 4.9 sec\n",
      "Final merge summary time: 1.35 sec\n",
      "TOTAL Sequential Time:   6.25 sec\n",
      "\n",
      "FINAL SUMMARY:\n",
      " Here is a combined summary of the text:\n",
      "\n",
      "**Introduction to the Transformer Model**\n",
      "\n",
      "The Transformer is a new neural network architecture introduced for sequence transduction tasks, such as machine translation. It is based solely on attention mechanisms, eliminating the need for recurrent neural networks (RNNs) and convolutional neural networks. The Transformer model consists of an encoder and a decoder, both composed of stacked layers.\n",
      "\n",
      "**Key Components of the Transformer Model**\n",
      "\n",
      "The Transformer model has several key components:\n",
      "\n",
      "1. **Self-Attention Mechanism**: allows the model to attend to different positions in the input sequence simultaneously and weigh their importance.\n",
      "2. **Scaled Dot-Product Attention**: a specific attention mechanism used in the Transformer, which computes attention weights by taking the dot product of queries and keys and applying a softmax function.\n",
      "3. **Multi-Head Attention**: an extension of self-attention, which applies multiple attention mechanisms in parallel and combines their outputs.\n",
      "4. **Position-Wise Feed-Forward Networks**: fully connected feed-forward networks applied to each position separately and identically.\n",
      "\n",
      "**Advantages of the Transformer Model**\n",
      "\n",
      "The Transformer model has several advantages over traditional sequence transduction models:\n",
      "\n",
      "1. **Parallelization**: The Transformer can be parallelized more easily than RNNs, reducing training time.\n",
      "2. **Performance**: The Transformer achieves state-of-the-art results on two machine translation tasks, with a significant improvement in BLEU score (a measure of translation quality).\n",
      "3. **Interpretability**: The Transformer model can yield more interpretable models, as individual attention heads appear to learn different tasks and exhibit behavior related to the syntactic and semantic structure of sentences.\n",
      "\n",
      "**Training and Evaluation of the Transformer Model**\n",
      "\n",
      "The Transformer model was trained on the WMT 2014 English-German dataset and the WMT 2014 English-French dataset. The model was trained using the Adam optimizer with a varied learning rate schedule. The results showed that the Transformer model achieved state-of-the-art results on both machine translation tasks, with a BLEU score of 28.4 on the English-German task and 41.0 on the English-French task.\n",
      "\n",
      "**Conclusion**\n",
      "\n",
      "The Transformer model represents a significant advancement in sequence transduction models, offering improved performance, parallelization, and efficiency. Its self-attention mechanism and multi-head attention architecture allow it to effectively weigh the importance of different input elements relative to each other, making it particularly well-suited for machine translation tasks.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pdfminer.high_level import extract_text\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ------------------------------\n",
    "# LLM Setup\n",
    "# ------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# PDF ‚Üí chunks\n",
    "# ------------------------------\n",
    "def load_pdf_chunks(folder: str, chunk_size: int = 1500):\n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".pdf\")]\n",
    "    all_chunks = []\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"Reading PDF: {f}\")\n",
    "        text = extract_text(os.path.join(folder, f)).replace(\"\\n\", \" \")\n",
    "        words = text.split()\n",
    "        \n",
    "        chunk, chunks = [], []\n",
    "        for w in words:\n",
    "            chunk.append(w)\n",
    "            if len(chunk) >= chunk_size:\n",
    "                chunks.append(\" \".join(chunk))\n",
    "                chunk = []\n",
    "        if chunk:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "\n",
    "        print(f\" ‚Üí Extracted {len(chunks)} chunks\")\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks[:15]  # limit for testing\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Sequential summarization\n",
    "# ------------------------------\n",
    "def summarize_chunk(text: str):\n",
    "    prompt = f\"Summarize this text:\\n{text}\"\n",
    "    return llm.invoke(prompt).content.strip()\n",
    "\n",
    "\n",
    "def sequential_summarizer(chunks):\n",
    "    chunk_summaries = []\n",
    "    timings = []\n",
    "\n",
    "    print(\"\\n--- Sequential LLM Summaries ---\\n\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {i+1}/{len(chunks)} ...\")\n",
    "        start = time.time()\n",
    "        summary = summarize_chunk(chunk)\n",
    "        end = time.time()\n",
    "\n",
    "        chunk_summaries.append(summary)\n",
    "        timings.append(end - start)\n",
    "\n",
    "        print(f\" ‚Üí Chunk time: {round(end-start, 2)} sec\")\n",
    "\n",
    "    t1 = time.time()\n",
    "\n",
    "    # Final merge summary\n",
    "    merge_start = time.time()\n",
    "    final_summary = llm.invoke(\n",
    "        f\"Combine these summaries into one:\\n\\n{chunk_summaries}\"\n",
    "    ).content.strip()\n",
    "    merge_end = time.time()\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"SEQUENTIAL SUMMARY TIMINGS\")\n",
    "    print(\"==============================\")\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "    print(f\"Chunk summarization time: {round(t1 - t0, 2)} sec\")\n",
    "    print(f\"Final merge summary time: {round(merge_end - merge_start, 2)} sec\")\n",
    "    print(f\"TOTAL Sequential Time:   {round(merge_end - t0, 2)} sec\")\n",
    "\n",
    "    return final_summary\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# RUN\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = r\"/Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs\"\n",
    "    chunks = load_pdf_chunks(folder)\n",
    "\n",
    "    print(f\"\\nTotal Chunks: {len(chunks)}\\n\")\n",
    "\n",
    "    final = sequential_summarizer(chunks)\n",
    "\n",
    "    print(\"\\nFINAL SUMMARY:\\n\", final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943a204",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "831b1c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading PDF: NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
      " ‚Üí Extracted 4 chunks\n",
      "\n",
      "Total chunks: 4\n",
      "\n",
      "==============================\n",
      "MAP-REDUCE SUMMARY TIMINGS\n",
      "==============================\n",
      "MAP time:      1.69 sec\n",
      "REDUCE time:   2.07 sec\n",
      "TOTAL time:    3.76 sec\n",
      "==============================\n",
      "\n",
      "FINAL SUMMARY:\n",
      " Here is a comprehensive summary of the paper \"Attention Is All You Need\" by Ashish Vaswani et al.:\n",
      "\n",
      "**Introduction**\n",
      "\n",
      "The paper proposes a new neural network architecture called the Transformer, which replaces traditional recurrent neural networks (RNNs) and convolutional neural networks (CNNs) with attention mechanisms. The Transformer achieves state-of-the-art results in machine translation tasks while being more parallelizable and requiring less training time.\n",
      "\n",
      "**Background**\n",
      "\n",
      "Traditional sequence transduction models use RNNs or CNNs to model dependencies between input and output sequences. However, these models have limitations, such as sequential computation and limited parallelization. The Transformer addresses these limitations by relying entirely on attention mechanisms.\n",
      "\n",
      "**Transformer Architecture**\n",
      "\n",
      "The Transformer consists of an encoder and a decoder, both composed of stacked identical layers. Each layer has two sub-layers: a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The decoder has an additional sub-layer that performs multi-head attention over the output of the encoder stack.\n",
      "\n",
      "**Attention Mechanism**\n",
      "\n",
      "The Transformer uses a new attention mechanism called Scaled Dot-Product Attention, which computes the output as a weighted sum of the values based on the compatibility of the query with the corresponding key. The Transformer uses multi-head attention, which runs multiple attention layers in parallel.\n",
      "\n",
      "**Advantages**\n",
      "\n",
      "The Transformer has several advantages over traditional models:\n",
      "\n",
      "1. **Parallelization**: The Transformer can be parallelized more easily, reducing training time.\n",
      "2. **Global dependencies**: The Transformer can model global dependencies between input and output sequences more effectively.\n",
      "3. **Reduced computation**: The Transformer requires less computation than traditional models.\n",
      "\n",
      "**Training Regime and Results**\n",
      "\n",
      "The Transformer was trained on the WMT 2014 English-German and English-French datasets. The model achieved state-of-the-art results on both translation tasks:\n",
      "\n",
      "1. **WMT 2014 English-to-German**: The Transformer achieves a BLEU score of 28.4, outperforming existing best results.\n",
      "2. **WMT 2014 English-to-French**: The Transformer achieves a BLEU score of 41.0, establishing a new single-model state-of-the-art.\n",
      "\n",
      "**Model Variations and Ablation Studies**\n",
      "\n",
      "The authors evaluated the importance of different components of the Transformer by varying the base model in different ways and measuring the change in performance on the English-German translation development set. The results showed that:\n",
      "\n",
      "* Single-head attention was 0.9 BLEU worse than the best setting.\n",
      "* Reducing the attention key size hurt model quality.\n",
      "* Bigger models were better.\n",
      "* Dropout was very helpful in avoiding over-fitting.\n",
      "\n",
      "**Key Components of the Transformer Model**\n",
      "\n",
      "The Transformer model consists of several key components:\n",
      "\n",
      "1. **Self-Attention Mechanism**: The model uses self-attention to weigh the importance of different input elements relative to each other.\n",
      "2. **Multi-Head Attention**: The model uses multi-head attention, which applies multiple attention functions in parallel, each with a different set of learned linear projections.\n",
      "3. **Position-Wise Feed-Forward Networks**: Each layer in the encoder and decoder contains a fully connected feed-forward network, applied to each position separately.\n",
      "4. **Embeddings and Softmax**: The model uses learned embeddings to convert input tokens to vectors, and a linear transformation and softmax function to produce output probabilities.\n",
      "5. **Positional Encoding**: The model uses sinusoidal positional encodings to inject information about the position of each token in the sequence.\n",
      "\n",
      "**Advantages of Self-Attention**\n",
      "\n",
      "The authors discussed the advantages of self-attention over recurrent and convolutional layers, including:\n",
      "\n",
      "* **Computational Complexity**: Self-attention is faster than recurrent layers when the sequence length is smaller than the representation dimensionality.\n",
      "* **Parallelization**: Self-attention can be parallelized more easily than recurrent layers.\n",
      "* **Path Length**: Self-attention has a shorter path length between long-range dependencies than recurrent and convolutional layers.\n",
      "\n",
      "Overall, the Transformer is a new and effective neural network architecture that replaces traditional RNNs and CNNs with attention mechanisms, achieving state-of-the-art results in machine translation tasks while being more parallelizable and requiring less training time.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict, TypedDict, Annotated\n",
    "from operator import add\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Send, Command\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from pdfminer.high_level import extract_text\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# ------------------------------\n",
    "# LLM Setup\n",
    "# ------------------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# PDF ‚Üí chunks\n",
    "# ------------------------------\n",
    "def load_pdf_chunks(folder: str, chunk_size: int = 1500):\n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".pdf\")]\n",
    "    all_chunks = []\n",
    "\n",
    "    for f in files:\n",
    "        print(f\"Reading PDF: {f}\")\n",
    "        text = extract_text(os.path.join(folder, f)).replace(\"\\n\", \" \")\n",
    "        words = text.split()\n",
    "\n",
    "        chunk, chunks = [], []\n",
    "        for w in words:\n",
    "            chunk.append(w)\n",
    "            if len(chunk) >= chunk_size:\n",
    "                chunks.append(\" \".join(chunk))\n",
    "                chunk = []\n",
    "        if chunk:\n",
    "            chunks.append(\" \".join(chunk))\n",
    "\n",
    "        print(f\" ‚Üí Extracted {len(chunks)} chunks\")\n",
    "        all_chunks.extend(chunks)\n",
    "\n",
    "    return all_chunks[:15] # limit for testing\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# MAP-REDUCE STATE\n",
    "# ------------------------------\n",
    "class MRState(TypedDict, total=False):\n",
    "    docs: List[str]\n",
    "    partials: Annotated[List[str], add]      # partial summaries\n",
    "    final_summary: str\n",
    "\n",
    "    # timers\n",
    "    map_start: float\n",
    "    map_end: float\n",
    "    reduce_start: float\n",
    "    reduce_end: float\n",
    "\n",
    "\n",
    "class WorkerState(TypedDict):\n",
    "    doc: str\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Nodes\n",
    "# ------------------------------\n",
    "def orchestrator(state: MRState) -> Command:\n",
    "    docs = state[\"docs\"]\n",
    "    sends = [Send(\"map_node\", {\"doc\": d}) for d in docs]\n",
    "\n",
    "    return Command(\n",
    "        update={\"map_start\": time.time()},\n",
    "        goto=sends\n",
    "    )\n",
    "\n",
    "\n",
    "def map_node(state: WorkerState) -> Dict:\n",
    "    \"\"\"LLM summarize each chunk\"\"\"\n",
    "    text = state[\"doc\"]\n",
    "    summary = llm.invoke(f\"Summarize:\\n{text}\").content.strip()\n",
    "    return {\"partials\": [summary]}\n",
    "\n",
    "\n",
    "def reduce_node(state: MRState) -> Dict:\n",
    "    reduce_start = time.time()\n",
    "\n",
    "    merged = llm.invoke(\n",
    "        f\"Combine these summaries into one:\\n\\n{state['partials']}\"\n",
    "    ).content.strip()\n",
    "\n",
    "    reduce_end = time.time()\n",
    "\n",
    "    return {\n",
    "        \"final_summary\": merged,\n",
    "        \"map_end\": state.get(\"map_end\", reduce_start),\n",
    "        \"reduce_start\": reduce_start,\n",
    "        \"reduce_end\": reduce_end\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# BUILD GRAPH\n",
    "# ------------------------------\n",
    "def build_graph():\n",
    "    builder = StateGraph(MRState)\n",
    "\n",
    "    builder.add_node(\"orchestrator\", orchestrator)\n",
    "    builder.add_node(\"map_node\", map_node)\n",
    "    builder.add_node(\"reduce_node\", reduce_node)\n",
    "\n",
    "    builder.add_edge(START, \"orchestrator\")\n",
    "    builder.add_edge(\"map_node\", \"reduce_node\")\n",
    "    builder.add_edge(\"reduce_node\", END)\n",
    "\n",
    "    return builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# RUN\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    folder = r\"/Users/sachinmishra/Desktop/LangGraph_Project_Based_Learning/financial_pdfs\"\n",
    "\n",
    "    chunks = load_pdf_chunks(folder)\n",
    "    print(f\"\\nTotal chunks: {len(chunks)}\")\n",
    "\n",
    "    graph = build_graph()\n",
    "    config = {\"configurable\": {\"thread_id\": \"mr_summarizer\"}}\n",
    "\n",
    "    total_start = time.time()\n",
    "    graph.invoke({\"docs\": chunks, \"partials\": []}, config=config)\n",
    "    total_end = time.time()\n",
    "\n",
    "    snapshot = graph.get_state(config)\n",
    "    v = snapshot.values\n",
    "\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"MAP-REDUCE SUMMARY TIMINGS\")\n",
    "    print(\"==============================\")\n",
    "    print(f\"MAP time:      {round(v['reduce_start'] - v['map_start'], 2)} sec\")\n",
    "    print(f\"REDUCE time:   {round(v['reduce_end'] - v['reduce_start'], 2)} sec\")\n",
    "    print(f\"TOTAL time:    {round(total_end - total_start, 2)} sec\")\n",
    "    print(\"==============================\\n\")\n",
    "\n",
    "    print(\"FINAL SUMMARY:\\n\", v[\"final_summary\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-project-based-learning (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
